{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf43a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20edb8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "# For simple regression problem\n",
    "TRAINING_POINTS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For fashion-MNIST and similar problems\n",
    "DATA_ROOT = '/data/csc4611/data/'\n",
    "FASHION_MNIST_TRAINING = '/data/csc4611/data/fashion_mnist_flattened_training.npz'\n",
    "FASHION_MNIST_TESTING = '/data/csc4611/data/fashion_mnist_flattened_testing.npz'\n",
    "CIFAR10_TRAINING = '/data/csc4611/data/cifar10_flattened_training.npz'\n",
    "CIFAR10_TESTING = '/data/csc4611/data/cifar10_flattened_testing.npz'\n",
    "CIFAR100_TRAINING = '/data/csc4611/data/cifar100_flattened_training.npz'\n",
    "CIFAR100_TESTING = '/data/csc4611/data/cifar100_flattened_testing.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab12d6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# With this block, we don't need to set device=DEVICE for every tensor.\n",
    "# But you will still need to avoid accidentally getting int types instead of floating-point types.\n",
    "torch.set_default_dtype(torch.float32)\n",
    "if torch.cuda.is_available():\n",
    "     torch.set_default_device(0)\n",
    "     print(\"Running on the GPU\")\n",
    "else:\n",
    "     print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728d2583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_training_data():\n",
    "    \"\"\"\n",
    "    This method simply rotates points in a 2D space.\n",
    "    Be sure to use L2 regression in the place of the final softmax layer before testing on this\n",
    "    data!\n",
    "    :return: (x,y) the dataset. x is a torch tensor where columns are training samples and\n",
    "             y is a torch tensor where columns are one-hot labels for the training sample.\n",
    "    \"\"\"\n",
    "    x = torch.randn((2, TRAINING_POINTS))\n",
    "    x1 = x[0:1, :].clone()\n",
    "    x2 = x[1:2, :]\n",
    "    y = torch.cat((-x2, x1), axis=0)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83095f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folded_training_data():\n",
    "    \"\"\"\n",
    "    This method introduces a single non-linear fold into the sort of data created by create_linear_training_data. Be sure to REMOVE the final softmax layer before testing on this data!\n",
    "    Be sure to use MSE in the place of the final softmax layer before testing on this\n",
    "    data!\n",
    "    :return: (x,y) the dataset. x is a torch tensor where columns are training samples and\n",
    "             y is a torch tensor where columns are one-hot labels for the training sample.\n",
    "    \"\"\"\n",
    "    x = torch.randn((2, TRAINING_POINTS))\n",
    "    x1 = x[0:1, :].clone()\n",
    "    x2 = x[1:2, :]\n",
    "    x2 *= 2 * ((x2 > 0).float() - 0.5)\n",
    "    y = torch.cat((-x2, x1), axis=0)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27ee7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_square():\n",
    "    \"\"\"\n",
    "    This is a square example in which the challenge is to determine\n",
    "    if the points are inside or outside of a point in 2d space.\n",
    "    insideness is true if the points are inside the square.\n",
    "    :return: (points, insideness) the dataset. points is a 2xN array of points and insideness is true if the point is inside the square.\n",
    "    \"\"\"\n",
    "    win_x = [2,2,3,3]\n",
    "    win_y = [1,2,2,1]\n",
    "    win = torch.tensor([win_x,win_y],dtype=torch.float32)\n",
    "    win_rot = torch.cat((win[:,1:],win[:,0:1]),axis=1)\n",
    "    t = win_rot - win # edges tangent along side of poly\n",
    "    rotation = torch.tensor([[0, 1],[-1,0]],dtype=torch.float32)\n",
    "    normal = rotation @ t # normal vectors to each side of poly\n",
    "        # torch.matmul(rotation,t) # Same thing\n",
    "\n",
    "    points = torch.rand((2,2000),dtype = torch.float32)\n",
    "    points = 4*points\n",
    "\n",
    "    vectors = points[:,np.newaxis,:] - win[:,:,np.newaxis] # reshape to fill origin\n",
    "    insideness = (normal[:,:,np.newaxis] * vectors).sum(axis=0)\n",
    "    insideness = insideness.T\n",
    "    insideness = insideness > 0\n",
    "    insideness = insideness.all(axis=1)\n",
    "    return points, insideness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b7ecd5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_dataset_flattened(train=True,dataset='Fashion-MNIST',download=False):\n",
    "    \"\"\"\n",
    "    :param train: True for training, False for testing\n",
    "    :param dataset: 'Fashion-MNIST', 'CIFAR-10', or 'CIFAR-100'\n",
    "    :param download: True to download. Keep to false afterwords to avoid unneeded downloads.\n",
    "    :return: (x,y) the dataset. x is a torch tensor where columns are training samples and\n",
    "             y is a torch tensor where columns are one-hot labels for the training sample.\n",
    "    \"\"\"\n",
    "    if dataset == 'Fashion-MNIST':\n",
    "        if train:\n",
    "            path = FASHION_MNIST_TRAINING\n",
    "        else:\n",
    "            path = FASHION_MNIST_TESTING\n",
    "        num_labels = 10\n",
    "    elif dataset == 'CIFAR-10':\n",
    "        if train:\n",
    "            path = CIFAR10_TRAINING\n",
    "        else:\n",
    "            path = CIFAR10_TESTING\n",
    "        num_labels = 10\n",
    "    elif dataset == 'CIFAR-100':\n",
    "        if train:\n",
    "            path = CIFAR100_TRAINING\n",
    "        else:\n",
    "            path = CIFAR100_TESTING\n",
    "        num_labels = 100\n",
    "    else:\n",
    "        raise ValueError('Unknown dataset: '+str(dataset))\n",
    "\n",
    "    if os.path.isfile(path):\n",
    "        print('Loading cached flattened data for',dataset,'training' if train else 'testing')\n",
    "        data = np.load(path)\n",
    "        x = torch.tensor(data['x'],dtype=torch.float32)\n",
    "        y = torch.tensor(data['y'],dtype=torch.float32)\n",
    "        pass\n",
    "    else:\n",
    "        class ToTorch(object):\n",
    "            \"\"\"Like ToTensor, only redefined by us for 'historical reasons'\"\"\"\n",
    "\n",
    "            def __call__(self, pic):\n",
    "                return torchvision.transforms.functional.to_tensor(pic)\n",
    "\n",
    "        if dataset == 'Fashion-MNIST':\n",
    "            data = torchvision.datasets.FashionMNIST(\n",
    "                root=DATA_ROOT, train=train, transform=ToTorch(), download=download)\n",
    "        elif dataset == 'CIFAR-10':\n",
    "            data = torchvision.datasets.CIFAR10(\n",
    "                root=DATA_ROOT, train=train, transform=ToTorch(), download=download)\n",
    "        elif dataset == 'CIFAR-100':\n",
    "            data = torchvision.datasets.CIFAR100(\n",
    "                root=DATA_ROOT, train=train, transform=ToTorch(), download=download)\n",
    "        else:\n",
    "            raise ValueError('This code should be unreachable because of a previous check.')\n",
    "        x = torch.zeros((len(data[0][0].flatten()), len(data)),dtype=torch.float32)\n",
    "        for index, image in enumerate(data):\n",
    "            x[:, index] = data[index][0].flatten()\n",
    "        labels = torch.tensor([sample[1] for sample in data])\n",
    "        y = torch.zeros((num_labels, len(labels)), dtype=torch.float32)\n",
    "        y[labels, torch.arange(len(labels))] = 1\n",
    "        np.savez(path, x=x.numpy(), y=y.numpy())\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2eb104",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class Timer(object):\n",
    "    def __init__(self, name=None, filename=None):\n",
    "        self.name = name\n",
    "        self.filename = filename\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.tstart = time.time()\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        message = 'Elapsed: %.2f seconds' % (time.time() - self.tstart)\n",
    "        if self.name:\n",
    "            message = '[%s] ' % self.name + message\n",
    "        print(message)\n",
    "        if self.filename:\n",
    "            with open(self.filename,'a') as file:\n",
    "                print(str(datetime.datetime.now())+\": \",message,file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3554e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # The code in this section should NOT be in a helper method.\n",
    "    # But you may choose to occassionally move helper methods before this as\n",
    "    # the code within them becomes stable.\n",
    "    #\n",
    "    # For this week's lab, however, you can likely keep ALL your code\n",
    "    # right here, with all your variables in the global scope \n",
    "    # for simplified debugging.\n",
    "    with Timer('Total time'):\n",
    "        # TODO: You may wish to make each TODO below its own pynb cell.\n",
    "        # TODO: Build your network.\n",
    "        dataset = 'Fashion-MNIST'\n",
    "    \n",
    "        # TODO: Select your datasource.\n",
    "        x_train, y_train = load_dataset_flattened(train=True, dataset=dataset, download=True)\n",
    "    \n",
    "        # TODO: Train your network.\n",
    "        with Timer('Training time'):\n",
    "            pass # Replace with your code to train\n",
    "    \n",
    "        # TODO: Sanity-check the output of your network.\n",
    "        # Compute the error on this test data:\n",
    "        x_test, y_test = load_dataset_flattened(train=False, dataset=dataset)\n",
    "    \n",
    "        # Report on GPU memory used for this script:\n",
    "        peak_bytes_allocated = torch.cuda.memory_stats()['active_bytes.all.peak']\n",
    "        print(f\"Peak GPU memory allocated: {peak_bytes_allocated} Bytes\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
